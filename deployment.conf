deployment {
    #Memory to be request for a node
	memory-per-node = 7000
	
	#arguments for the jvm, make sure you are not using -Xmx -Xms
	# because these will be set depending on the memory-per-node.
	jvm-arguments = "-XX:+AggressiveOpts -XX:+AlwaysPreTouch -XX:+UseNUMA -XX:-UseBiasedLocking -XX:MaxInlineSize=1024 -XX:-UseBiasedLocking -XX:+UnlockExperimentalVMOptions -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:+CMSIncrementalPacing -XX:+CMSIncrementalMode -XX:ParallelGCThreads=10 -XX:ParallelCMSThreads=10"
	
	#number of nodes to be requested
	number-of-nodes = 5

    #files which will be copied to the cluster
	copy-files = []
	
	#algorith which will be executed.
	# Must be of type com.signalcollect.deployment.Algorithm and a scala object.
	algorithm = "com.signalcollect.deployment.PageRankExample$"
	
	#parameters which will be passed to the algorithm as Map[String,String]
	algorithm-parameters {
		#"parameter" = "value"
		#"number-of-readers" = "2"
		#"length-data" = "26172280241"
		#"length-data" = "110135128"
	}
	
    #implementation of the Cluster to be used
	#cluster = "com.signalcollect.deployment.LocalCluster" 
	#cluster = "com.signalcollect.deployment.LeaderCluster"
	cluster = "com.signalcollect.deployment.yarn.YarnCluster"
	#cluster = "com.signalcollect.deployment.amazon.AmazonCluster"
	
	#after this timeout in seconds the execution will shutdwon 
	timeout = 400
	
	#settings for the akka configuration
    akka {
      
	  port: 2552
      kryo-initializer = "com.signalcollect.configuration.KryoInit"
      kryo-registrations = [
        #"some.class.to.be.registered"
      ]
      serialize-messages = true
      loggers = ["com.signalcollect.logging.AkkaLog4JAdapter"]
      log-level = "info"
	}
	
	
	
	#----------- Yarn specific Settings ------------
	
	#name of your application
	application-name = "signal-collect-yarn-deployment"
	
	#memory requested for the leader
	leader-memory = 7000
	
	#the factor of how much more memory will be requested,
	# this prevents that the NodeManager is killing your application if it exceeds the memory limit.
	requested-memory-factor = 1.1
	
	#Class which will be executed in a container
	container-class = "com.signalcollect.deployment.NodeContainerApp"
	
	#path to your jar file
	path-to-jar = "target/scala-2.11/signal-collect-yarn-assembly-1.0-SNAPSHOT.jar"
	
	#working directory in the hdfs.
	# if your not using an absolute path hadoop will take /user/yourusername as home directory.
	hdfspath = "/ddis/tbachmann/signal-collect-yarn-deployment"
	
	#your username in hadoop.
	#pay attention this feature is quite hacky.
	#if it is not working, it takes your username of your local computer.
	user = "tbachmann"
	
	#experimental feature, files which are already in hdfs will be downloaded to the containers.
	files-on-hdfs = []
	
	#overrides the default hadoop configuration.
	# The default setting can be found here: http://hadoop.apache.org/docs/r2.4.1/hadoop-yarn/hadoop-yarn-common/yarn-default.xml
	hadoop-overrides {
  	  yarn {
  		resourcemanager {
  			#host = "127.0.0.1"
  			host = "salvador.ifi.uzh.ch"
  			#address = "127.0.0.1:8032"
  			address = "salvador.ifi.uzh.ch:8032"
  			scheduler {
  			  address = "salvador.ifi.uzh.ch:8030"
  			}
  		}
  	  }
  	  fs.defaultFS = "hdfs://tentacle.ifi.uzh.ch:9000"
  	}
}

# Testing parameters
testing{

  # if this is true, a local MiniCluster will be used
  useMiniCluster = true
  
  # if this is true a jar will be created out of the project.
  # make sure you set  the dependcies used by your project
  createJarOnTheFly = false
  
  # this dependencies are deployed if you create the jar on the fly. you can set several dependencies seperated with a ':'.
  dependency = "../signal-collect-yarn-dependencies/target/scala-2.11/signal-collect-yarn-assembly-1.0-SNAPSHOT.jar:../signal-collect/target/scala-2.11/signal-collect-2.1-SNAPSHOT.jar"
  
  #experimental feature which keeps the dependenices in the hdfs.
  onHdfs = false
}	
